{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pc3IRj89i_Oe"
      },
      "outputs": [],
      "source": [
        "# feature_engineering.py\n",
        "# Feature engineering with polynomial and interaction terms\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "\n",
        "def feature_engineering(X_train, X_test, num_cols):\n",
        "    # Initialize PolynomialFeatures for interaction and polynomial terms\n",
        "    poly_interaction = PolynomialFeatures(degree=3, include_bias=False, interaction_only=True)\n",
        "    poly_full = PolynomialFeatures(degree=3, include_bias=False, interaction_only=False)\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Create lists to hold new features\n",
        "    new_train_features = []\n",
        "    new_test_features = []\n",
        "\n",
        "    for col in num_cols:\n",
        "        if col in X_train.columns:\n",
        "            # Interaction features\n",
        "            train_interaction = poly_interaction.fit_transform(X_train[[col]])\n",
        "            test_interaction = poly_interaction.transform(X_test[[col]])\n",
        "\n",
        "            # Scale\n",
        "            train_interaction_scaled = scaler.fit_transform(train_interaction)\n",
        "            test_interaction_scaled = scaler.transform(test_interaction)\n",
        "\n",
        "            # Create DataFrames for the interaction features\n",
        "            train_interaction_df = pd.DataFrame(train_interaction_scaled, columns=[f\"{col}_interact_{i}\" for i in range(train_interaction_scaled.shape[1])])\n",
        "            test_interaction_df = pd.DataFrame(test_interaction_scaled, columns=[f\"{col}_interact_{i}\" for i in range(test_interaction_scaled.shape[1])])\n",
        "            # Append to the list\n",
        "            new_train_features.append(train_interaction_df)\n",
        "            new_test_features.append(test_interaction_df)\n",
        "\n",
        "\n",
        "            # Polynomial features including interaction\n",
        "            train_poly = poly_full.fit_transform(X_train[[col]])\n",
        "            test_poly = poly_full.transform(X_test[[col]])\n",
        "\n",
        "            # Scale\n",
        "            train_poly_scaled = scaler.fit_transform(train_poly)\n",
        "            test_poly_scaled = scaler.transform(test_poly)\n",
        "\n",
        "            # Create DataFrames for the polynomial features\n",
        "            train_poly_df = pd.DataFrame(train_poly_scaled, columns=[f\"{col}_poly_{i}\" for i in range(train_poly_scaled.shape[1])])\n",
        "            test_poly_df = pd.DataFrame(test_poly_scaled, columns=[f\"{col}_poly_{i}\" for i in range(test_poly_scaled.shape[1])])\n",
        "\n",
        "            # Append to the lists\n",
        "            new_train_features.append(train_poly_df)\n",
        "            new_test_features.append(test_poly_df)\n",
        "\n",
        "    # Concatenate the new features to the original datasets\n",
        "    X_train = pd.concat([X_train] + new_train_features, axis=1)\n",
        "    X_test = pd.concat([X_test] + new_test_features, axis=1)\n",
        "\n",
        "    return X_train, X_test\n",
        "\n",
        "# Sample usage:\n",
        "# X_train, X_test = feature_engineering(X_train, X_test, num_cols)"
      ]
    }
  ]
}